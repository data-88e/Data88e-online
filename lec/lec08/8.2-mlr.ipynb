{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f8e679",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\" id=\"nb-header\">\n",
    "    <tr style=\"background-color: transparent;\"><td>\n",
    "        <img src=\"https://data-88e.github.io/assets/images/blue_text.png\" width=\"250px\" style=\"margin-left: 0;\" />\n",
    "    </td><td>\n",
    "        <p style=\"text-align: right; font-size: 10pt;\"><strong>Economic Models</strong>, EdX<br>\n",
    "            Dr. Eric Van Dusen <br>\n",
    "            Vaidehi Bulusu <br>\n",
    "        Akhil Venkatesh <br>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c46c6f-9a0f-4a72-a2c7-ad61db5e8cd7",
   "metadata": {},
   "source": [
    "# Lecture Notebook 8.2: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8175e15",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "In simple linear regression, we're only considering one independent variable. We're essentially assuming that this is the only variable that affects our dependent variable. Going back to the price and quantity demanded example, while price does have a huge effect on demand, there are other factors that also affect demand including income taxes, sales taxes, advertising, prices of related goods, etc. In the context of regression, because we are not including these variables in our model, they are called **omitted variables**.\n",
    "\n",
    "Omitted variables cause 2 main problems:\n",
    "\n",
    "- The regression parameters end up being inaccurate (biased) because of something called omitted variable bias. Your regression estimates for the slope and intercept are higher or lower than the actual values because of omitted variables (we are generally only concerned about the slope).\n",
    "\n",
    "\n",
    "- They prevent you from inferring a causal association between the independent and dependent variables. In other words, you can't say that it's *because* of an increase in price that your quantity demanded decreased as there are so many other factors – like the change in the price of a related good – that could be causing the decrease in demand.\n",
    "\n",
    "To try to eliminate omitted variable bias from our model, we take simple linear regression a step further: to multiple linear regression. In multiple linear regression, we are including more indepedent variables – variables we think are confounding variable that we've omitted – to reduce omitted variable bias.\n",
    "\n",
    "Let's look at multiple linear regression in Python using a new dataset on earnings and various other factors (check out the [data description](https://wps.pearsoned.com/wps/media/objects/11422/11696965/empirical/empex_tb/CPS08_Description.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475d7c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>year</th> <th>ahe</th> <th>bachelor</th> <th>female</th> <th>age</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1992</td> <td>11.1888</td> <td>1       </td> <td>0     </td> <td>29  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1992</td> <td>10     </td> <td>1       </td> <td>0     </td> <td>33  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1992</td> <td>5.76923</td> <td>0       </td> <td>0     </td> <td>30  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1992</td> <td>1.5625 </td> <td>0       </td> <td>0     </td> <td>32  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1992</td> <td>14.9573</td> <td>1       </td> <td>0     </td> <td>31  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (15311 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cps = Table.read_table(\"CPS.csv\")\n",
    "cps.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d8fd1",
   "metadata": {},
   "source": [
    "Say we want to look at the relationship between age and earnings (the `ahe` column which is the average hourly earnings). We would expect whether or not a person has a bachelor's degree to be a confounding variable as those with a bachelor's degree typically earn more than those with only a high school degree. This is how we would do multiple linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ead0f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.153</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.153</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1381.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jul 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:58:54</td>     <th>  Log-Likelihood:    </th> <td> -54106.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15316</td>      <th>  AIC:               </th> <td>1.082e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15313</td>      <th>  BIC:               </th> <td>1.082e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.2711</td> <td>    0.708</td> <td>   -1.796</td> <td> 0.073</td> <td>   -2.659</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    6.6590</td> <td>    0.135</td> <td>   49.333</td> <td> 0.000</td> <td>    6.394</td> <td>    6.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4621</td> <td>    0.024</td> <td>   19.551</td> <td> 0.000</td> <td>    0.416</td> <td>    0.508</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5161.829</td> <th>  Durbin-Watson:     </th> <td>   1.523</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>21800.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.619</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.866</td>  <th>  Cond. No.          </th> <td>    316.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.153\n",
       "Model:                            OLS   Adj. R-squared:                  0.153\n",
       "Method:                 Least Squares   F-statistic:                     1381.\n",
       "Date:                Tue, 25 Jul 2023   Prob (F-statistic):               0.00\n",
       "Time:                        00:58:54   Log-Likelihood:                -54106.\n",
       "No. Observations:               15316   AIC:                         1.082e+05\n",
       "Df Residuals:                   15313   BIC:                         1.082e+05\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.2711      0.708     -1.796      0.073      -2.659       0.116\n",
       "x1             6.6590      0.135     49.333      0.000       6.394       6.924\n",
       "x2             0.4621      0.024     19.551      0.000       0.416       0.508\n",
       "==============================================================================\n",
       "Omnibus:                     5161.829   Durbin-Watson:                   1.523\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21800.024\n",
       "Skew:                           1.619   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.866   Cond. No.                         316.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = cps.select(\"bachelor\", \"age\").values # This is how we include multiple independent variables in our model\n",
    "y_2 = cps.column(\"ahe\")\n",
    "model_2 = sm.OLS(y_2, sm.add_constant(x_2))\n",
    "result_2 = model_2.fit()\n",
    "result_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0da5c5",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "\n",
    "One type of variable commonly used in econometrics are dummy variables. These are variables that take a value of either 0 or 1 to indicate the presence of absence of a category. For example, take col: it takes the value of 1 to indicate that a person went to college and 0 to indicate that a person didn't go to college.\n",
    "\n",
    "Let's do a regression of `ahe` on only `bachelor` (the dummy variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572ebfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.132</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.132</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2323.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jul 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:58:54</td>     <th>  Log-Likelihood:    </th> <td> -54294.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15316</td>      <th>  AIC:               </th> <td>1.086e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15314</td>      <th>  BIC:               </th> <td>1.086e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   12.4593</td> <td>    0.090</td> <td>  138.210</td> <td> 0.000</td> <td>   12.283</td> <td>   12.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    6.5831</td> <td>    0.137</td> <td>   48.194</td> <td> 0.000</td> <td>    6.315</td> <td>    6.851</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5289.393</td> <th>  Durbin-Watson:     </th> <td>   1.538</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>22667.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.657</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.953</td>  <th>  Cond. No.          </th> <td>    2.49</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.132\n",
       "Model:                            OLS   Adj. R-squared:                  0.132\n",
       "Method:                 Least Squares   F-statistic:                     2323.\n",
       "Date:                Tue, 25 Jul 2023   Prob (F-statistic):               0.00\n",
       "Time:                        00:58:54   Log-Likelihood:                -54294.\n",
       "No. Observations:               15316   AIC:                         1.086e+05\n",
       "Df Residuals:                   15314   BIC:                         1.086e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         12.4593      0.090    138.210      0.000      12.283      12.636\n",
       "x1             6.5831      0.137     48.194      0.000       6.315       6.851\n",
       "==============================================================================\n",
       "Omnibus:                     5289.393   Durbin-Watson:                   1.538\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22667.410\n",
       "Skew:                           1.657   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.953   Cond. No.                         2.49\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3 = cps.select(\"bachelor\").values\n",
    "y_3 = cps.column(\"ahe\")\n",
    "model_3 = sm.OLS(y_3, sm.add_constant(x_3))\n",
    "result_3 = model_3.fit()\n",
    "result_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead27b0",
   "metadata": {},
   "source": [
    "The coefficient (or slope) on `bachelor` is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850735f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.583093534494762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_3.params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c337ed",
   "metadata": {},
   "source": [
    "This means that the people in our sample with a bachelor's degree earn around $6.583 more per hour than those with only a high school degree.\n",
    "\n",
    "An interesting fact about dummy variables is that we can calculate this coefficient another way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01bc17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.583093534494745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for bachelor = 1 and find mean earnings\n",
    "b_1_mean = np.mean(cps.where(\"bachelor\", 1).column(\"ahe\"))\n",
    "\n",
    "# Filter for bachelor = 0 and find mean earnings\n",
    "b_0_mean = np.mean(cps.where(\"bachelor\", 0).column(\"ahe\"))\n",
    "\n",
    "# Take the difference in the mean earnings\n",
    "diff = b_1_mean - b_0_mean\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852c04b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(result_3.params[1], 5) == np.round(diff, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f24fc",
   "metadata": {},
   "source": [
    "These two values are pretty much the same! This is because the coefficient on a dummy x-variable is just equal to the difference of the mean of the y-variable when x = 1 and x = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa9074",
   "metadata": {},
   "source": [
    "### `pd.get_dummies()`\n",
    "\n",
    "We can convert categorical variables in our dataset to dummy variables using the pd.get_dummies() function. This function gives you a table showing the presence or absence of dummy variables for that category for each observation in the dataset. Here's an example of converting the year values to dummies. 1 indicates that the person was surveyed in that year (e.g. the first 4 people in the dataset were surveyed in 1992 according to the table below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c82784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1992, 2008])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = cps.column(\"year\")\n",
    "np.unique(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba97a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1992</th>\n",
       "      <th>2008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1992  2008\n",
       "0     1     0\n",
       "1     1     0\n",
       "2     1     0\n",
       "3     1     0\n",
       "4     1     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_dummies = pd.get_dummies(year)\n",
    "year_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed4f0b",
   "metadata": {},
   "source": [
    "Let's do the same for the age variable. Take the first row as an example: since 1 is under 29, it means that that person is 29 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6cdbd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 26, 27, 28, 29, 30, 31, 32, 33, 34])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = cps.column(\"age\")\n",
    "np.unique(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399e0739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   25  26  27  28  29  30  31  32  33  34\n",
       "0   0   0   0   0   1   0   0   0   0   0\n",
       "1   0   0   0   0   0   0   0   0   1   0\n",
       "2   0   0   0   0   0   1   0   0   0   0\n",
       "3   0   0   0   0   0   0   0   1   0   0\n",
       "4   0   0   0   0   0   0   1   0   0   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_dummies = pd.get_dummies(age)\n",
    "age_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4c5cc",
   "metadata": {},
   "source": [
    "### Dummy Variable Trap\n",
    "\n",
    "One problem you may run into when using dummy variables is called the dummy variable trap. This happens when you include variables for all the values of the dummy variable: for example, you include col, which takes on a value of 1 if the person went to college, as well as notcol, which takes on a value of 1 if the person didn't go to college.\n",
    "\n",
    "This causes redundancy as you can express one independent variable as a linear combination of another independent variable. In this case:\n",
    "\n",
    "$$ notcol = 1 - col$$\n",
    "\n",
    "This means that there is a perfect correlation between these two independent variables which reuslts in perfect multicollinearity. In general, multicollinearity occurs any time there is a high correlation between the independent variables in your model. It causes your regression estimates to be highly inaccurate.\n",
    "\n",
    "Let's see what happens in Python when multicollinearity happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5823b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1992</th>\n",
       "      <th>2008</th>\n",
       "      <th>ahe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.188811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.957265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1992  2008        ahe\n",
       "0     1     0  11.188811\n",
       "1     1     0  10.000000\n",
       "2     1     0   5.769231\n",
       "3     1     0   1.562500\n",
       "4     1     0  14.957265"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_dummies[\"ahe\"] = np.array(cps.column(\"ahe\"))\n",
    "year_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e7518a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>ahe</td>       <th>  R-squared:         </th> <td>   0.167</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.167</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3068.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Jul 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:58:55</td>     <th>  Log-Likelihood:    </th> <td> -53977.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15316</td>      <th>  AIC:               </th> <td>1.080e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15314</td>      <th>  BIC:               </th> <td>1.080e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   10.2008</td> <td>    0.044</td> <td>  230.644</td> <td> 0.000</td> <td>   10.114</td> <td>   10.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1992</th>  <td>    1.4255</td> <td>    0.070</td> <td>   20.343</td> <td> 0.000</td> <td>    1.288</td> <td>    1.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>  <td>    8.7753</td> <td>    0.070</td> <td>  125.748</td> <td> 0.000</td> <td>    8.638</td> <td>    8.912</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4968.655</td> <th>  Durbin-Watson:     </th> <td>   1.764</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20461.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.561</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.724</td>  <th>  Cond. No.          </th> <td>6.23e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.92e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    ahe   R-squared:                       0.167\n",
       "Model:                            OLS   Adj. R-squared:                  0.167\n",
       "Method:                 Least Squares   F-statistic:                     3068.\n",
       "Date:                Tue, 25 Jul 2023   Prob (F-statistic):               0.00\n",
       "Time:                        00:58:55   Log-Likelihood:                -53977.\n",
       "No. Observations:               15316   AIC:                         1.080e+05\n",
       "Df Residuals:                   15314   BIC:                         1.080e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         10.2008      0.044    230.644      0.000      10.114      10.288\n",
       "1992           1.4255      0.070     20.343      0.000       1.288       1.563\n",
       "2008           8.7753      0.070    125.748      0.000       8.638       8.912\n",
       "==============================================================================\n",
       "Omnibus:                     4968.655   Durbin-Watson:                   1.764\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20461.443\n",
       "Skew:                           1.561   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.724   Cond. No.                     6.23e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.92e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3 = year_dummies[[1992, 2008]] # We are including dummy variables for each value of year\n",
    "y_3 = year_dummies[\"ahe\"]\n",
    "model_3 = sm.OLS(y_3, sm.add_constant(x_3))\n",
    "result_3 = model_3.fit()\n",
    "result_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad78d3",
   "metadata": {},
   "source": [
    "Python detected the multicollinearity and gave you a warning. A solution is to just drop one of the dummy variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
